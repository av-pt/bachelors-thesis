\chapter{Background}\label{ch:background}
% Authorship Verification
\section{Authorship Verification}\label{sec:authorship-verification}
In our world a large amount of communication and information transfer is done through a visual medium: text.
This was not always the case.
According to \cite{owidliteracy}, for most of history, reading and writing was reserved to an elite and associated with power.
Through the spread of public education over time, increasingly more people were able to read and write.
World-wide literacy rates are estimated to have been at 12\% in 1820 and have risen to 86\% in 2016.
\cite{buringh2009charting} estimates that the number of books produced annually in Western Europe in the sixth and seventh centuries was only around 120.
In contrast, and not only due to the invention of letterpress printing with movable type, the production in 1790 was at a peak of 20,000,000 books per year.
These historical processes gave rise to the linguistic branch of Stylometry, the analysis of "an author's work based especially on the recurrence of particular turns of expression or trends of thought"\footnote{\url{https://www.merriam-webster.com/dictionary/stylometry}}.
The worth of profiling authors can be exemplified with a court case from 1979 (cit. needed, this is from wikipedia).
The American linguist Roger Shuy was able to infer that the author of a ransom note linked to a kidnapping case had to be well-educated and from Akron, Ohio.
Using this information, the offender was caught and later confessed the crime.\\
With the adoption of computers by the linguistic community, stylometry was increasingly done automatically.
The wide availability of training data and the increasing speed of computers allowed for more involved and complex stylometric methods (cit. needed) [holmes1998].
Nowadays, Author Identification (/Authorship Analysis?), aiming at determining authors of given texts, is consolidated as a subbranch of stylometry.
According to \cite{bevendorff2020shared}, it can be further parted into the four disciplines \textit{Authorship Attribution}, \textit{Authorship Verification}, \textit{Authorship Obfuscation}, and \textit{Obfuscation Evaluation}.
Of these tasks only \textit{Authorship Verification} is of interest to our research.
It is defined as: "[G]iven a pair of documents, determine whether they are written by the same author"\footnote{
Further definitions from \cite{bevendorff2020shared} (move to appendix?):
\begin{itemize}
  \item \textit{Authorship Attribution}: given a document and a set of candidate authors, determine which of them wrote  the  documen
  \item \textit{Authorship Obfuscation}: given a document and a set of documents from the same author, paraphrase the former so that its author cannot be identified anymore
  \item \textit{Obfuscation Evaluation}: devise and implement performance measures that quantify safeness, soundness, and/or sensibleness of an obfuscation software
\end{itemize}
}.
According to \cite{stein2019unbiasedGutenbergCorpus}, this task was first proposed in 2004 by \cite{koppel2004unmasking}, and thus is a rather recent development.
As stated in \cite{bevendorff2020shared}, the PAN series of shared tasks\footnote{\url{https://pan.webis.de/}}\footnote{Wikipedia: "originally, plagiarism analysis, authorship identification, and near-duplicate detection, later more generally workshop on uncovering plagiarism, authorship, and social software misuse", \url{https://en.wikipedia.org/wiki/Stylometry\#PAN}} included Authorship Verification from 2013 to 2015 and picked them back up with PAN2020, with a planned total of three tasks over the years 2020 to 2022.
In the course of reintegrating the task to PAN, a new data format has been devised, which we will use in our research.//
Roughly based on the notation in \cite{bevendorff2020shared} the task can be formalized as follows.
Given a text pair $(d_1, d_2)$, classify it to ${True, False}$, i.e.,\ approximate the target function $\phi{}:(d_1, d_2)\to\{True, False\}$ where $\phi(d_1, d_2)=True$ iff $d_1$ and $d_2$ have the same author.
We call an algorithm that approximates $\phi$ an Authorship Verification classifier, or AV classifier for short.
Note that we do not classify actual authors but only the fact of whether they are different or not.
Thus, the goal is to implant those mechanics into an AV classifier that are applicable for classification universally, regardless of the style of one specific author.

% Phonetics
\section{Phonetics}\label{sec:phonetics}
As defined in \cite{ogrady2017introToLinguistics}, phonetics\footnote{Merriam-Webster: "borrowed from New Latin ph$\bar{\mbox{o}}$n$\bar{\mbox{e}}$ticus "(of written characters) representing speech sounds rather than ideas,"[...]", \url{https://www.merriam-webster.com/dictionary/phonetics}. (Etymology is a bit more complicated.)} is the branch of linguistics concerned with "the inventory and structure of the sounds of speech" (the following definitions are mostly taken from that book, too; do i need to cite it again?).
Not all sounds humans can articulate are present in the worlds languages.
Yet a wide range of these sounds, estimated to 600 consonants and 200 vowels, occur in human language.
Note that phonetics is different from phonology, in that phonology examines how sounds create meaning in a language.
Two subbranches of phonetics are articulatory phonetics and acoustic phonetics.
The former concerns itself with the physiological processes involved in speech production while the latter examines acoustic characteristics of speech.
In our research we focus on articulatory phonetics.\\
The distinct sounds of which a spoken utterance is made up are called \textit{phones}.
On a more abstract level, linguists segment speech into \textit{phonemes}.
Phonemes are defined as the smallest unit of sound distinguishing meaning in the words of a language.
Swapping a phoneme in a word changes its meaning, while replacing a phone with a different one does not necessarily alter its meaning.
Those sets of phones that do not evoke a change of meaning when exchanged are called \textit{allophones} of their respective phonemes.
For example, the alveolar nasal consonant [n] and the dental nasal consonant [\textipa{\|[n}] are allophones of the phoneme /n/ as they are not used to differentiate meaning in English -- [\textipa{w2n}] and [\textipa{w2\|[n}] both point to the same concept "one".
However, the alveolar nasal consonant [n] and the bilabial nasal consonant [m] are different, contrasting phonemes -- [\textipa{m\ae{}p}] and [\textipa{n\ae{}p}] indicate the two distinct concepts "map" and "nap".
While phones are universal, phonemes are language specific (source?).\\
As hypothesized in the introduction, we suspect that information valuable for identifying authorship exists on the phonetic level.
Because Authorship Verification classifiers use text as input, we want to utilize methods to extract phonetically relevant features from these texts.
One possible way of achieving this is with phonetic transcriptions.
For our purposes, these are transformations assigning a symbol to each sound of a text as if the text was spoken aloud.
Phonetic transcriptions can be seen as data reduction methods.
By applying them, we anticipate that the phonetically relevant features stay apparent while other, less relevant features stand out less.
In total, we use seven phonetic transcription systems of different granularity.
The \textit{narrower} a transcription, the more closely it follows the phonetic details of an utterance.
This often leads to the system having a bigger alphabet, such as the IPA described below.
The \textit{broader} a transcription, the more it generalizes phonetic features.
(Table \ref{tab:system_characteristics} shows more information on the properties of these systems, from most narrow to most broad. (mentioned below))\\

% IPA
The most widely used phonetic transcription system is the International Phonetic Alphabet (\textbf{IPA}). % Cite O'Grady?! I mean, this is fact...
As outlined in \cite{ipa1999ipaHandbook}, it was developed by the International Phonetic Association founded in 1886.
It serves as a system to notate the sounds of languages in an internationally agreed-upon manner.
Pulmonic consonants - consonants initiated by a buildup of pressure from the lungs - are distinguished in their place and manner of articulation.
The place of articulation describes the position in the vocal tract where the sound is produced.
For example, a bilabial sound, such as the "b" in "beer", is articulated with both lips whereas a glottal sound, such as the "h" in "hello", is articulated all the way back at the glottis.  % Explain glottis in footnote?
The manner of articulation includes several factors regarding distinctive ways of sound production.
To give an example, a plosive, such as the "p" in "explosion", is created by completely stopping the airflow, building up pressure and suddenly releasing said pressure.
The IPA also differentiates between voiced and voiceless consonants such as the first phonemes in the words "vast" and "fast".
In a similar way, non-pulmonic consonants and vowels are organized on scales such as position and manner of articulation.
This way, a system to classify arbitrary sounds of a language has been created.
With 155 symbols, its alphabet is the largest of the transcription systems considered in this thesis.
Therefore, the produced transcriptions are usually the narrowest.
It should be noted that when using the IPA system a transcription can be much more detailed than just using the correct symbols for the phonemes.
Using diacritics, many other qualities of speech, such as the roundedness of the lips, can be indicated.
Creating accurate and detailed transcriptions of a given speech sample on the level of phones is a difficult task usually done manually by linguists.
This ties into a problem we have found in our research that we shall discuss later on.
To achieve more stable results, we use a slightly broader version of the IPA omitting prosodic markers and diacritics. % Note exact size?
Table \ref{tab:example_transcriptions} shows examples for IPA and the other transcription systems as used in our research.\\


% Sound Classes
Because of its detailed nature, IPA transcriptions contain a lot of information.
Continuing with the idea of reducing phonetically irrelevant information, we also employ broader transcription systems.
The following ones can be categorized as sound class systems organizing speech sounds into linguistically-informed classes.\\
% Dolgo
According to \cite{list2012multiple}, the term sound class was first devised and detailed in \cite{dolgopolsky1986dolgoOriginal}.
For conciseness, we will use the term more generically as defined above.
The Dolgopolsky sound class system (\textbf{Dolgo}) was introduced in \cite{dolgopolsky1986dolgoOriginal} (Paper not found).
Based on empirical data, phonemes are organized into ten classes, so that the difference between sounds inside of a class is less than the difference between classes.
% Based on empirical data, phonemes are organized into the classes, so that 'phonetic correspondences inside a "type" are more regular than between different types'.
(Info is from List paper above, a bit unclear if "correspondence relations" simply means "coocurrences (of phonemes)".)
We use a slightly extended version of the original $Dolgo$ sound class system, as implemented in \cite{list2018cltsIntro}.
It includes an eleventh class for vowels and is compatible with all IPA symbols including common diacritics.
A list of the $Dolgo$ sound classes with examples for corresponding phonemes can be seen in \ref{tab:dolgo_sound_classes}.


\begin{table}
\caption{$Dolgo$ sound classes, adopted from \cite{list2010dolgoRefined} with the eleventh category "V" added.}
\label{tab:dolgo_sound_classes}
\centering\small
\begin{tabular}{@{}c@{\hspace{3\tabcolsep}}cc@{}} % Use @{\hspace{2\tabcolsep}} to double the spacing
\toprule
\bf Symbol & \bf Example phonemes (IPA) & \bf Category \\
\midrule
P & p, b, f                     & labial obstruents \\
T & d, t, \textipa{T, D}        & dental obstruents \\
S & s, z, \textipa{S, Z}        & sibilants \\
K & k, g, \textipa{ts, tS}      & velar obstruents, dental and alveolar affricates \\
M & m                           & labial nasal \\
N & n, \textipa{\textltailn, N} & remaining nasals \\
R & r, l                        & liquids \\
W & v, u                        & voiced labial fricative and initial rounded vowels \\
J & j                           & palatal approximant \\
H & h, \textipa{H, N}(repeat?)  & laryngeals and initial velar nasal \\
V & \textipa{A, E, I}           & other vowels (simple and diphtongs) \\
\bottomrule
\end{tabular}
\end{table}


% ASJP
The Automated Similarity Judgment Program is a project aiming to classify the worlds languages introduced in \cite{brown2008asjpCode}.
As of June (26,) 2021, it consists of a database comprising 40-word lists of core vocabulary translated to 9,788 languages.
The word lists include meanings such as "I", "drink", and "water".
Each word is transcribed using the asjpCode transcription system.
This way, phonetic similarities between language pairs can be computed.
Language-similarity-trees created with ASJP produce near expert-level classifications.
AsjpCode (\textbf{ASJP}) consists of 34 consonant and 7 vowel symbols.
It can be interpreted as a simplified variant of the IPA system, with the difference that some symbols represent a broader class of speech sounds.
For example, "N" represents the velar nasal [\textipa{N}] directly, while "o" represents all rounded and unrounded mid and low back vowels [\textipa{7, 2, A, o, O, 6}].
Another benefit of asjpCode, although not directly influential to our research, is that it consists of only those symbols which are found on a standard QWERTY keyboard.
This facilitates manual transcription.\\
% CV
Lastly, the \textbf{CV} sound class system assigns the symbol "C" to consonant phonemes and the symbol "V" to vowel phonemes as done in \cite{list2017lingpy}.
With a binary alphabet it is the broadest of the transcription systems we use.\\

% Soundex
Apart from these systems we also examine the impact of three simple phonetic algorithms.
These algorithms were invented to match words of similar pronunciation in English.
The \textbf{Soundex} algorithm, patented by Robert C. Russell in \cite{russel1918soundex} and \cite{russel1922soundex}, was devised for indexing names.
By grouping names by phonetic similarity instead of alphabetically, the time needed to search for a given name would be shortened.
Also, similar sounding names that are written differently would be organized into the same categories simplifying access when, for example, only a spoken name is given.
A word is represented by a code consisting of a capital letter, the first character of the word, and three digits.
The digits, ranging from 1 to 6, represent sound classes of letters occurring later in the word.
Table \ref{tab:soundex_sound_classes} shows these classes in more detail.
The process of assigning these codes roughly functions as follows.
The first letter in the word is used as the beginning letter of the code.
The first letter and all occurrences of the letters "a", "e", "i", "o", "u", "y", "h", and "w" are removed.
The remaining letters are encoded using the mapping from \ref{tab:soundex_sound_classes}.
If two equal sound classes appear next to each other, the second occurrence is removed.
The resulting code is truncated to a length of four characters in total.
If the code is shorter than four characters it is filled up with trailing zeros.
(Citation needed: patent differenciates between m and n, algorithms do not (-> class 5))\\

\begin{table}
\caption{Soundex sound classes as used in our research.}
\label{tab:soundex_sound_classes}
\centering\small
\begin{tabular}{@{}c@{\hspace{3\tabcolsep}}cc@{}} % Use @{\hspace{2\tabcolsep}} to double the spacing
\toprule
\bf Symbol & \bf Associated characters & \bf Category \\
\midrule
1 & b, f, p, v             & labials, labio-dentals \\
2 & c, g, j, k, q, s, x, z & gutturals, sibilants \\
3 & d, t                   & dental-mutes \\
4 & l                      & palatal-fricatives \\
5 & m, n                   & nasals \\
6 & r                      & dental-fricatives \\
\bottomrule
\end{tabular}
\end{table}

The Refined Soundex algorithm (\textbf{RefSoundex})(citation needed) improves upon its predecessor, with the main difference being that the resulting codes are no longer truncated or extended to a length of 4 but instead retain their original length.
Also, the number of the sound classes is increased to nine, instead of six, leading to a narrower transcription.
The alternate mapping can be seen in \ref{tab:refsoundex_sound_classes}.
Lastly, the digit sequence following the first character also includes this character's sound class symbol.
The word "and", for example, is transcribed to "A086", not "A86".
\cite{howard2019refsoundexSource1} traces the origins of Refined Soundex back to an implementation in the Apache Commons Library as noted in \cite{fossati2008refsoundexSource2}, but indicates that the idea of modifying the sound classes already appeared in \cite{zobel1995refsoundexSource3}.\\

\begin{table}
\caption{Refined Soundex sound classes as used in our research.}
\label{tab:refsoundex_sound_classes}
\centering\small
\begin{tabular}{@{}c@{\hspace{3\tabcolsep}}cc@{}} % Use @{\hspace{2\tabcolsep}} to double the spacing
\toprule
\bf Symbol & \bf Associated characters & \bf Category \\
\midrule
0 & a, e, i, o, u, y, h, w & (vowel-like?) \\
1 & b, p                   & labials \\
2 & f, v                   & labio-dentals \\
3 & c, k, s                & (?) \\
1 & g, j                   & (gutturals?) \\
2 & q, x, z                & (?) \\
3 & d, t                   & dental-mutes \\
4 & l                      & palatal-fricatives \\
5 & m, n                   & nasals \\
6 & r                      & dental-fricatives \\
\bottomrule
\end{tabular}
\end{table}

% Metaphone
\textbf{Metaphone} is also a phonetic indexing algorithm first published in \cite{philips1990metaphone} (Paper not found).
It improves on the Soundex family of algorithms by taking a larger number of inconsistencies and edge-cases of English pronunciation into account.
Also, its focus does not only lie on indexing names but rather English words in general.
It consists of a series of roughly 27 (see source code) context-aware transformations, sequentially replacing phonetically similar patterns with representative symbols or removing them if they are not pronounced (unpronounced?).
For example, one such transformation is removing the first letter of a word if that word starts with "KN", "GN", "PN", "AE", or "WR".
$Metaphone$'s alphabet consists of only 21 symbols -- 16 for consonants and 5 for vowels -- representing classes of phonemes (speech sounds?).
Vowel symbols only appear at the beginning of transcribed words.
Metaphone was later superseded by Double Metaphone and the closed-source Metaphone 3, both of which use a substantially larger rule set.

For normalization, we remove all inter-word punctuation in the texts.
Intra-word punctuation, such as in "don't", is phonetically significant and thus not removed.
For brevity, we refer to all systems described above as phonetic transcription systems.
In addition to the phonetic transcriptions above, we also create three other conversions for comparison:
\begin{itemize}
  \item \textbf{P}: Removing punctuation
  \item \textbf{PL}: Removing punctuation and lemmatizing the occurring words
  \item \textbf{PLS}: Removing punctuation, lemmatizing, and removing stop words
\end{itemize}
We handle $Verbatim$ text and the three non-phonetic conversions the same way as transcribed text.


% Statistical analysis
% Vocab reduction on some corpus
% Vocab size counting: Space Tokenize, count tokens that are not punctuation and are not numbers, upper- / lower-case is dismissed. This leaves soundex tokens in. Texts of a pair are concatenated
To better understand the characteristics of phonetic transcription systems, we conducted some preliminary investigations (only one investigation at the moment).
Figure X insert plot X shows the vocabulary size of the texts from the Gutenberg dataset used later.
Table \ref{tab:system_characteristics} shows the vocabulary size scaling factors (abreviated as VSSF) (and more)
% ToDo:
% Add labels with VSSF to vocab size plots
% Add VSSFs to table
% Add function to count character length of text
% Maybe rename vocab_sizes.py to characteristics.py
% Change "properties" in text to "characteristics"


% Describe verbatim
% Describe higher, describe lower
% Calculate percentages, "IPA increases vocab size by 18.5%..."
% IPA is larger because narrow
% Why is asjp larger? Look at least (/ most) common words
% Say why lemma Lemma_punct (punct. is ignored) lemma_punct_stop have the same height (stop a bit lower, lacks stop words...)
% Refsoundex is higher because uncapped length
% soundex is capped at length 4
%As soundex is capped at 4, max vocab size is 26k types

% cv has only two letters
% Forward reference that this information will be used later on.
% Other statistics: text length (in characters)

\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}

\begin{table}
\caption{Characteristics of the transcription systems used. "Verbatim" represents original English text. Punctuation and whitespace not included in alphabet size.}
\label{tab:system_characteristics}
\centering\small
\begin{tabular}{@{}l@{\hspace{1\tabcolsep}}lll@{}} % Use @{\hspace{2\tabcolsep}} to double the spacing
\toprule
\bf System & \bf Alphabet size & \bf \specialcell{VSSF (absolute)\\Gutenberg} & \bf \specialcell{VSSF (absolute)\\Fan-fiction} \\
\midrule
$IPA$        & >100(?) & 1.2688 (60675) &  \\
$ASJP$       & 41(?)   & 1.1688 (55894) &  \\
$Verbatim$   & 26(?)   & 1.0    (47820) &  \\
$P$          & 26(?)   & 0.9977 (47710) &  \\
$PL$         & 26(?)   & 0.8002 (38264) &  \\
$PLS$        & 26(?)   & 0.7968 (38101) &  \\
$Dolgo$      & 11      & 0.7588 (36288) &  \\
$RefSoundex$ & 36      & 0.6157 (29441) &  \\
$Metaphone$  & 21      & 0.5534 (26464) &  \\
$Soundex$    & 32      & 0.0889 (4250)  &  \\
$CV$         & 2       & 0.0409 (1954)  &  \\
\bottomrule
\end{tabular}
\end{table}



% "Clever Features"
% - n-gram approach instead of word-tokenization
% - phonetic richness / complexity (over time)
% - vowel-phoneme over time
% - sound-classes over time (e.g. hard sounds / plosives compared to soft sounds)
% - sound classes: consonants and place of articulation (e.g. labial, nasal, ...)


\begin{table}
\caption{Example transcriptions.}
\label{tab:example_transcriptions}
\centering\small
\begin{tabular}{@{}l@{\hspace{3\tabcolsep}}l@{}} % Use @{\hspace{2\tabcolsep}} to double the spacing
\toprule
\bf System & \bf Transcription \\
\midrule
Verbatim   & Wake and rise, and step into the green outdoors.\footnote{From \cite{ieee1969sentences}, Appendix C, List 58.5} \\
IPA        & \textipa{weIk 2nd \*raIz 2nd stEp Intu D2 g\*rin aUtdO\*rz} \\
Dolgo      & WVK VNT RVS VNT STVP VNTV TV KRVN VTTVRS \\
ASJP       & wek ond raz ond stEp intu 8o grin atdorz \\
CV         & CVC VCC CVC VCC CCVC VCCV CV CCVC VCCVCC \\
Soundex    & W200 A530 R200 A530 S310 I530 T000 G650 O362 \\
RefSoundex & W030 A086 R9030 A086 S3601 I0860 T60 G4908 O06093 \\
Metaphone  & WK ANT RS ANT STP INT 0 KRN OTTRS \\
\bottomrule
\end{tabular}
\end{table}

% Supra-segmental features

% Warum und Wie wird beides verbunden?
% Maybe put this in Introduction!
% Integrating phonetics into stylometric methods is not an entirely new endeavour...
% Hypothesis: Phonetic preference

% Discuss problem 1: text to phonemes is difficult and information is lost.
As discussed above, converting speech to a detailed and accurate phonetic transcription is hard.
Even more difficult is creating said transcription from text instead of speech.
...

% Discuss problem 2: We examine mostly sub-segmental features. Author freedom is small. Maybe supra-segmental features are better.
% ladefoged p278: phonetics of the individual [... are ...] difficult to describe een with spectrograms of the person's speech.